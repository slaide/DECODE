# run the notebooks with:
  # $ conda activate decode_env
  # $ python -m decode.neuralfitter.train.live_engine -p [path to your params].yaml

# to setup use of forked decode
#   install conda decode_env, according to regular DECODE instructions
#   then remove this directory: anaconda3/envs/decode_env_fork/lib/python3.8/site-packages/decode 
#   and instead insert a softlink/shortcut to the forked DECODE folder in its place: $ ln -s DECODE_fork/decode anaconda3/envs/decode_env_fork/lib/python3.8/site-packages/decode
#   to enable this environment in a jupyter notebook
#     run this anywhere: $ conda install -c anaconda ipykernel
#     then run this from within the anaconda environment that you want to use in jupyter: $ python -m ipykernel install --user --name=decode_env
#     in a jupyter notebook, you will then see a button/dropdown where you can change the kernel of the running notebook instance, which you need to change to the name of the environment you specified in the line above
#   done
#   requires torchvision package for pranet, which can be installed with $ conda install --name decode_env_fork torchvision # which installs the cpu version, but that is fine for now
#   required to align phase contrast images with fluorescence images $ conda install -c conda-forge --name decode_env_fork opencv-python
#   required to make cells cell-shaped in 3d (measures shortest distance of a point in 1/2/3d to the nearest border to another color-labelled region): $ conda install -c conda-forge --name decode_env_fork edt # github: https://github.com/seung-lab/euclidean-distance-transform-3d/

# decode/utils/reference_files/reference.yaml contains very similar information (but without the added comments)
CameraPreset:
Camera:
  baseline: 100.0
  convert2photons: true # "convert back to photon units" converts simulated pixel values to photon units (values are simulated in ADUs)
  e_per_adu: 0.3
  em_gain: # blank for cMOS cameras
  mirror_dim:   # this field is only active during fitting per inference .py file
  px_size:
  - 65.0
  - 65.0
  qe: 1.0 # quantum efficiency
  read_sigma: 74.4 # median read (readout) noise (in electrons?)
  spur_noise: 0.002 # spurious noise (background noise in camera sensors)
Evaluation:
  dist_ax: 500.0 # i think this is the distance within which emitter positions are matched for evaluation (relevant for classification, and upper bound for localization precision)
  dist_lat: 250.0
  dist_vol:
  match_dims: 3
Hardware:
  device: cuda
  device_ix: 0
  device_simulation: cuda
  num_worker_train: 4 # change
  torch_threads: 4 # change
  unix_niceness: 0 # this is a unix process thing (generally dont worry about it. see python os.nice())
  torch_multiprocessing_sharing_strategy:  # if you get multiprocessing errors, increase ulimit or set to 'file_system'
HyperParameter:
  arch_param: # what do these do?
    activation: ReLU
    depth:
    depth_shared: 2
    depth_union: 2
    depth_bg:
    init_custom: true
    initial_features: 48
    initial_features_bg:
    inter_features: 48
    norm:
    norm_bg:
    norm_bg_groups:
    norm_groups:
    norm_head:
    norm_head_groups:
    p_dropout:
    pool_mode: StrideConv # can be StrideConv or MaxPool
    upsample_mode: nearest # assuming this can be nearest, bilinear, linear..?
    recpt_bg:
    skip_gn_level:
    up_mode: upsample
    use_last_nl:
  architecture: SigmaMUNet
  batch_size: 64
  channels_in: 3 # number of frames used as input for second part of network (default: 3, set to 1 to 'disable' use of multiple frames)
  channels_out:
  chweight_stat:
    - 1.0
    - 1.0
  disabled_attributes:
  ds_lifetime: # what is ds? dataset? then what is dataset lifetime? (also: never used anywhere)
  epoch_0: # what is this? if training is continued from a checkpoint, the checkpoint also determines the index of the current epoch, maybe this was a debug parameter for development?
  epochs: 10000 # max number of epochs (also terminates when learning has stagnated)
  fgbg_factor:
  grad_mod: true
  emitter_label_photon_min: 100.0
  loss_impl: MixtureModel
  learning_rate_scheduler: StepLR
  learning_rate_scheduler_param:
    step_size: 10 # every 10 epochs \
    gamma: 0.9 # reduce learning rate to 90% of former value
  max_number_targets: 250 # what is this exactly? max number of predicted fluorophores? (which would be a post-processing parameter)
  moeller_gradient_rescale: false
  opt_param:
    lr: 0.0006
    weight_decay: 0.1
  optimizer: AdamW
  photon_threshold:
  pseudo_ds_size: 10000 # number of images sampled for training
  root_experiments_folder: experiments
InOut:
  calibration_file: data/calibration/flowcell_p65nm_z25nm_3dcal.mat  # cubic spline coefficients
  checkpoint_init:   # initialise from checkpoint (i.e. resume training)
  experiment_out: network/2020-07-06  # main output dir
  model_init:
PostProcessing: LookUp  # (blank) for no post-processing or LookUp, Consistency
PostProcessingParam:
  raw_th: 0.5
Scaling:  # if some values are missing they will be auto-set as described in the respective comments below
  input_scale:  # intensity_mu / 50
  input_offset:  # bg_uniform (mean)
  bg_max:  # 1.2 * upper limit of bg val
  phot_max:  # intensity_mu + 8 * sigma
  z_max:  # 1.2 * upper simulation extent
Simulation:
  bg_uniform: 90.0 # can tuple of values, or a single value
  density: # unit? also density xor emitter_av must be specified
  emitter_av: 20 # average number of emitters per frame (?)
  emitter_extent: # x/y should not be changed (apparently)
  - - -0.5
    - 39.5
  - - -0.5
    - 39.5
  - - -750
    - 750
  img_size: # input size
  - 40
  - 40
  intensity_mu_sig: # tuple
  - 10000.0
  - 3000.0
  intensity_th:
  lifetime_avg: 2.0 # average number of frames the emitter are alive for (with the blinking emitter model)
  mode: acquisition  # acquisition / samples (argument determines frame range size calculation)
  photon_range:
  psf_extent: # x/y should not be changed (apparently)
  - - -0.5
    - 39.5
  - - -0.5
    - 39.5
  -
  roi_size:  # if none, take the whole range of calibration
  roi_auto_center: false
  xy_unit: px
TestSet:
  mode:  simulated  # static / simulated
  test_size: 512 # sample this many frames 
  frame_extent: # x/y should not be changed (apparently)
  - - -0.5
    - 39.5
  - - -0.5
    - 39.5
  - null
  img_size:
    - 40
    - 40

